{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d2655f",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a54654",
   "metadata": {},
   "source": [
    "## General overview\n",
    "In this homework you will learn how to implement and test simple neural network models for solving supervised problems. It is divided in two tasks.\n",
    "\n",
    "* **Regression task**: \n",
    "the regression model will consist in a simple function approximation problem, similar to the one discussed during the Lab practices. \n",
    "\n",
    "* **Classification task**: \n",
    "the classification model will consist in a simple image recognition problem, where the goal is to correctly classify images of Zalando's article images (Fashion MNIST). \n",
    "\n",
    "In both cases, but especially for the classification problem, you should explore the use of advanced optimizers and regularization methods (e.g., initialization scheme, momentum, ADAM, early stopping, L2, L1 / sparsity, dropoutâ€¦) to improve convergence of stochastic gradient descent and promote generalization. Learning hyperparameters should be tuned using appropriate search procedures, and final accuracy should be evaluated using a cross-validation setup. For the image classification task, you can also implement more advanced convolutional architectures and explore feature visualization techniques to better understand how the deep network is encoding information at different processing layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8498fefc",
   "metadata": {},
   "source": [
    "\n",
    "## Grade\n",
    "The maximum grade for this homework will be **8 points**. Points will be assigned based on the correct implementation of the following items:\n",
    "*\t2 pt: implement basic regression and classification tasks\n",
    "*\t2 pt: explore advanced optimizers and regularization methods (both tasks)\n",
    "*\t1 pt: optimize hyperparameters using grid/random search and cross-validation (both tasks)\n",
    "*\t2 pt: implement CNN for classification task\n",
    "*\t1 pt: visualize weight histograms, activation profiles and receptive fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b2b83",
   "metadata": {},
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a53c6a5",
   "metadata": {},
   "source": [
    "* The goal is to train a neural network that maps an input image (from fashionMNIST) to one of ten classes (multi-class classification problem with mutually exclusive classes).\n",
    "* Define a proper loss (e.g. [torch.nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss))\n",
    "* Also here, consider to create a validation set from you training data, or use a k-fold cross-validation strategy.\n",
    "* Pay attention to the shape, data type and output values range. If needed, modify them accordingly to your implementation (read carefully the documentation of the layers that you use, e.g. [torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)).\n",
    "* Explore different optimizers, acivation functions, network architectures. Analyze the effect of different regularization methods, such as dropout layers, random transformations (image rotation, scaling, add noise...) or L2 regularization (weight decay)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4539e8e7",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stffimport torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9004a1",
   "metadata": {},
   "source": [
    "Download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST('classifier_data', train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.FashionMNIST('classifier_data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a67c5",
   "metadata": {},
   "source": [
    "How to get an image and the corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0edc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0\n",
    "image = train_dataset[sample_index][0]\n",
    "label = train_dataset[sample_index][1]\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.imshow(image, cmap='Greys')\n",
    "print(f\"SAMPLE AT INDEX {sample_index}\")\n",
    "print(f\"LABEL: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d8d8e9",
   "metadata": {},
   "source": [
    "The output of the dataset is a PIL Image, a python object specifically developed to manage and process images. PyTorch supports this format, and there are useful transforms available natively in the framework: https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "If you want, you can easily convert a PIL image to a numpy array and entirely ignore the PIL object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ae7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numpy = np.array(image)\n",
    "\n",
    "print(f'Numpy array shape: {image_numpy.shape}')\n",
    "print(f'Numpy array type: {image_numpy.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26783943",
   "metadata": {},
   "source": [
    "To transform a PIL Image directly to a PyTorch tensor, instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "image_tensor = to_tensor(image)\n",
    "\n",
    "print(f'PyTorch tensor shape: {image_tensor.shape}')\n",
    "print(f'PyTorch tensor type: {image_tensor.dtype}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
